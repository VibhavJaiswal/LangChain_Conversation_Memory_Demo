{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "snBYHptMnyJb",
   "metadata": {
    "id": "snBYHptMnyJb"
   },
   "source": [
    "# **Demo: LangChain Memory**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Dld3JlxbT53P",
   "metadata": {
    "id": "Dld3JlxbT53P"
   },
   "source": [
    "#__Description:__\n",
    "In this activity, you will learn how to use different types of memory in LangChain. Each type of memory serves a unique purpose and can be used in different scenarios depending on the requirements of your conversation model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cVXoe4RUn3O8",
   "metadata": {
    "id": "cVXoe4RUn3O8"
   },
   "source": [
    "# **Steps to Perform:**\n",
    "\n",
    "1. Import the Necessary Modules\n",
    "2. Initialize the Chat Model\n",
    "3. Define ConversationBufferMemory\n",
    "4. Define ConversationBufferWindowMemory with a Window Size of 1\n",
    "5. Define ConversationTokenBufferMemory with a Maximum Token Limit of 30\n",
    "6. Define ConversationSummaryBufferMemory with a Maximum Token Limit of 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eyRI2cM0UL1J",
   "metadata": {
    "id": "eyRI2cM0UL1J"
   },
   "source": [
    "# **Step 1: Import the Necessary Modules**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f85e3c5a",
   "metadata": {
    "id": "f85e3c5a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory, ConversationBufferWindowMemory, ConversationTokenBufferMemory, ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cFIuxtHkUTIc",
   "metadata": {
    "id": "cFIuxtHkUTIc"
   },
   "source": [
    "# **Step 2: Initialize the Chat Model**\n",
    "\n",
    "\n",
    "*   Initialize the chat model with a temperature of 0.0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ab3e43e",
   "metadata": {
    "id": "3ab3e43e"
   },
   "outputs": [],
   "source": [
    "\n",
    "llm = ChatOpenAI(temperature=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1H_MPaTsUZdr",
   "metadata": {
    "id": "1H_MPaTsUZdr"
   },
   "source": [
    "# **Step 3: Define ConversationBufferMemory**\n",
    "\n",
    "\n",
    "*   Utilize it in a ConversationChain for making predictions and printing the memory buffer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32525373",
   "metadata": {
    "id": "32525373",
    "outputId": "94f91c9d-0550-4f10-d677-c75aa61498c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hello, my name is Raghav\n",
      "AI: Hello Raghav! It's nice to meet you. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory() # Saves the entire conversation\n",
    "conversation = ConversationChain(llm=llm, memory = memory)\n",
    "conversation.predict(input=\"Hello, my name is Raghav\")\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9878fd9e-de7c-481e-a62c-12f3005f48c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hello, my name is Raghav\n",
      "AI: Hello Raghav! It's nice to meet you. How can I assist you today?\n",
      "Human: What is 2+2?\n",
      "AI: 2 + 2 equals 4. Is there anything else you would like to know?\n"
     ]
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 2+2?\")\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4e14216-e1b5-4333-919f-a494a3f270f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hello, my name is Raghav\n",
      "AI: Hello Raghav! It's nice to meet you. How can I assist you today?\n",
      "Human: What is 2+2?\n",
      "AI: 2 + 2 equals 4. Is there anything else you would like to know?\n",
      "Human: What is my name?\n",
      "AI: Your name is Raghav.\n"
     ]
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87ae7c71-0f6c-4731-8d0f-439a9212f858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hello, my name is Raghav\n",
      "AI: Hello Raghav! It's nice to meet you. How can I assist you today?\n",
      "Human: What is 2+2?\n",
      "AI: 2 + 2 equals 4. Is there anything else you would like to know?\n",
      "Human: What is my name?\n",
      "AI: Your name is Raghav.\n",
      "Human: can you add 100 to the number\n",
      "AI: Sure! Adding 100 to 4 gives us 104. Is there anything else you would like me to calculate for you?\n"
     ]
    }
   ],
   "source": [
    "conversation.predict(input=\"can you add 100 to the number\")\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7515c8b-6e3c-48cd-aab9-c119d0df59f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff1cf824-6554-4837-81d8-bfa9148d29b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.json\",\"w\") as file:\n",
    "    json.dump(memory.buffer,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627f00f4-2409-4524-9c06-1e3dabba85bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fHKrpuvIUfny",
   "metadata": {
    "id": "fHKrpuvIUfny"
   },
   "source": [
    "# **Step 4: Define ConversationBufferWindowMemory with a Window Size of 1**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c406c55",
   "metadata": {
    "id": "3c406c55",
    "outputId": "dd708430-a4a1-4a89-d140-f144c40bcd9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hello\\nAI: How are you?\\nHuman: I'm good, thanks\\nAI: Great to hear!\"}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationBufferWindowMemory(k=2)\n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"How are you?\"})\n",
    "memory.save_context({\"input\": \"I'm good, thanks\"}, {\"output\": \"Great to hear!\"})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6595612b-8c2d-4c44-9e97-eaa80486ca52",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12c46043-77e9-455e-b925-de58f1120c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hello, my name is Raghav\n",
      "AI: Hello Raghav! It's nice to meet you. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "conversation = ConversationChain(llm=llm, memory = memory)\n",
    "conversation.predict(input=\"Hello, my name is Raghav\")\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d5bcd3f-057a-4e3f-8028-6d30bb522309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: What is 2+2?\n",
      "AI: 2 + 2 equals 4. Is there anything else you would like to know?\n"
     ]
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 2+2?\")\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fd3e202-d4b1-4c76-9dca-3ef0bed1198e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: What is my name?\n",
      "AI: I'm sorry, I do not have access to personal information such as your name. Is there anything else you would like to ask?\n"
     ]
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cTgW8BUtvk",
   "metadata": {
    "id": "07cTgW8BUtvk"
   },
   "source": [
    "# **Step 5: Define ConversationTokenBufferMemory with a Maximum Token Limit of 30**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e01a67ba",
   "metadata": {
    "id": "e01a67ba",
    "outputId": "7342f887-ab75-4eb9-9b6d-730085ab98fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Machine Learning is what?!\\nAI: Incredible!\\nHuman: Neural Networks are what?\\nAI: Fascinating!\\nHuman: AI Assistants are what?\\nAI: Impressive!'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=3000)\n",
    "memory.save_context({\"input\": \"Machine Learning is what?!\"}, {\"output\": \"Incredible!\"})\n",
    "memory.save_context({\"input\": \"Neural Networks are what?\"}, {\"output\": \"Fascinating!\"})\n",
    "memory.save_context({\"input\": \"AI Assistants are what?\"}, {\"output\": \"Impressive!\"})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "N5B6Y6g9U15e",
   "metadata": {
    "id": "N5B6Y6g9U15e"
   },
   "source": [
    "# **Step 6: Define ConversationSummaryBufferMemory with a Maximum Token Limit of 100**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "713bc684",
   "metadata": {
    "id": "713bc684",
    "outputId": "e781ab8b-d02d-4f2e-b04b-d14a75a82917"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"System: The human greets the AI and asks what's up. The AI responds that it's just working. The human then inquires about the agenda for the day.\\nAI: There is a meeting at 10am with your design team. You will need your sketch designs ready. 11am-2pm have time to work on your LangChain project which will go smoothly because Langchain is such a powerful tool. At 2pm, lunch at the sushi restaurant with a client who is flying in to meet you to understand the latest in AI. Be sure to bring your tablet to show the latest LLM demo.\"}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schedule = \"There is a meeting at 10am with your design team. \\\n",
    "You will need your sketch designs ready. \\\n",
    "11am-2pm have time to work on your LangChain \\\n",
    "project which will go smoothly because Langchain is such a powerful tool. \\\n",
    "At 2pm, lunch at the sushi restaurant with a client who is flying \\\n",
    "in to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your tablet to show the latest LLM demo.\"\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
    "memory.save_context({\"input\": \"Hi\"}, {\"output\": \"Hello\"})\n",
    "memory.save_context({\"input\": \"What's up?\"}, {\"output\": \"Not much, just working\"})\n",
    "memory.save_context({\"input\": \"What is on the agenda today?\"}, {\"output\": f\"{schedule}\"})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uxHfpP_fVBNB",
   "metadata": {
    "id": "uxHfpP_fVBNB"
   },
   "source": [
    "# **Conclusion**\n",
    "You learned how to use different types of memory in LangChain and how to implement and use ConversationBufferMemory, ConversationBufferWindowMemory, ConversationTokenBufferMemory, and ConversationSummaryBufferMemory. You’ve also understood how ConversationSummaryBufferMemory can handle larger pieces of information, such as a daily schedule. This knowledge will help you effectively utilize LangChain’s memory capabilities in your projects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db224b5-bfba-434e-bf99-f4fb57d924f2",
   "metadata": {
    "id": "4db224b5-bfba-434e-bf99-f4fb57d924f2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 [3.10]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
